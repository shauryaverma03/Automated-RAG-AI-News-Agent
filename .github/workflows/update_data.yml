name: Hourly News Scraper

on:
  schedule:
    - cron: '0 * * * *'  # Runs at minute 0 of every hour
  workflow_dispatch:      # Allows you to click "Run Now" manually

jobs:
  scrape-and-embed:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Critical: Allows the bot to push changes
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install Libraries
        run: pip install -r requirements.txt
        
      - name: Run Automation Script
        env:
          PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_REPO_ID: ${{ secrets.HF_REPO_ID }}
        run: python ingest_and_push.py
        
      # --- SAVE THE JSON BOOK TO GITHUB ---
      - name: Commit JSON Data
        run: |
          # 1. SET YOUR IDENTITY (You MUST change these two lines!)
          git config --global user.name "shauryaverma03"
          git config --global user.email "shauryaverma036@gmail.com"
          
          # 2. Pull latest changes to avoid conflicts
          git pull
          
          # 3. Add the JSON Knowledge Base file
          git add knowledge_base.json
          
          # 4. Commit and Push
          git commit -m "ðŸ“š Added new articles to JSON Data" || echo "No news to commit"
          git push
